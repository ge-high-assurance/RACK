#!/usr/bin/env python3
#
# Copyright (c) 2020, Galois, Inc.
#
# All Rights Reserved
#
# This material is based upon work supported by the Defense Advanced Research
# Projects Agency (DARPA) under Contract No. FA8750-20-C-0203.
#
# Any opinions, findings and conclusions or recommendations expressed in this
# material are those of the author(s) and do not necessarily reflect the views
# of the Defense Advanced Research Projects Agency (DARPA).

import argparse
import logging
import sys
from pathlib import Path
from typing import Callable, List, NoReturn, Tuple

import semtk

from custom_formatter import stream_handler
import git_helpers as git
from ontology_changes.ontology_change import Commit, LOGGER_ID, stylize_file_name
from rack.commits import commits_in_chronological_order


logger = logging.getLogger(LOGGER_ID)
logger.addHandler(stream_handler)
logger.propagate = False

parser = argparse.ArgumentParser()

parser.add_argument(
    "--old-ref",
    help="Old reference to migrate from",
    type=str,
    required=True,
)

parser.add_argument(
    "--new-ref",
    help="More recent reference to migrate up to",
    type=str,
    required=True,
)


parser.add_argument(
    "--from-folder",
    help="Folder of JSON files to migrate",
    type=str,
)

parser.add_argument(
    "--list-changes-only",
    help="Have the tool only list changes in a human-readable format",
    action="store_true",
)

parser.add_argument(
    "--log-level",
    help="Assign logger severity level",
    type=str,
    default="INFO",
)

parser.add_argument(
    "--to-folder",
    help="Folder to output the migrated JSON files",
    type=str,
)

parser.add_argument(
    "--format-for-wiki",
    help="Format the output of --list-changes-only to the RACK wiki format",
    action='store_true',
)

args = parser.parse_args()


try:
    logging.basicConfig(level=args.log_level)
except ValueError:
    logger.error("Bad log level specified")
    sys.exit(1)


old_commit_id = git.get_commit_id(args.old_ref)
new_commit_id = git.get_commit_id(args.new_ref)


def get_commit_by_id(
    commits: List[Commit],
    commit_id: str,
    abort: Callable[[], NoReturn],
) -> Tuple[int, Commit]:
    try:
        return next(
            commit for commit in enumerate(commits) if commit[1].number == commit_id
        )
    except StopIteration as e:
        print(e)
        abort()


def make_abort(message: str) -> Callable[[], NoReturn]:
    def abort() -> NoReturn:
        print(message)
        sys.exit(1)

    return abort


def find_recorded_commits_between(
    old_commit_id: str,
    new_commit_id: str,
) -> List[Commit]:

    commit_ids_in_chronological_order: List[str] = []

    # This callback will be called for all commits in the git history, from
    # newer ones to older ones.  Therefore, prepending will yield commits in
    # chronological order.
    def on_commit(commit_id: str) -> None:
        commit_ids_in_chronological_order.insert(0, commit_id)

    git.traverse_commits(
        new_commit=new_commit_id,
        old_commit=old_commit_id,
        on_commit=on_commit,
    )

    # Now all we need to do is to filter out all our recorded commits that are
    # within this window.
    return [
        commit
        for commit in commits_in_chronological_order
        if any(
            [
                commit_id == commit.number
                for commit_id in commit_ids_in_chronological_order
            ]
        )
    ]


commits_to_consider_in_chronological_order = find_recorded_commits_between(
    old_commit_id=old_commit_id,
    new_commit_id=new_commit_id,
)
commits_to_consider_in_git_log_order = reversed(
    commits_to_consider_in_chronological_order
)


if len(commits_to_consider_in_chronological_order) == 0:
    print("We did not find any commits in the range you specified, aborting.")
    sys.exit(1)


if args.list_changes_only:

    if args.format_for_wiki:
        print(
            """
<!-- markdownlint-disable first-line-heading -->
<!-- markdownlint-disable line-length -->
<!-- markdownlint-disable no-bare-urls -->

This page's content is automatically generated by the `rack_migrate` script.  Do
not edit it manually!

This captures all changes to the RACK ontology (and **only** the RACK ontology),
in reverse chronological order.  Even within each section, commits are ordered
from most recent to oldest.  Changes prior to version 4.0 have not been tracked.

---

"""
        )

    for commit in commits_to_consider_in_git_log_order:
        if len(commit.changes) > 0:
            print(
                f"\n[Commit {commit.number}](https://github.com/ge-high-assurance/RACK/commit/{commit.number})\n"
            )
            for change in commit.changes:
                print(f"- {change.text_description()}")
        if commit.tag:
            this_tag = f"[{commit.tag}](https://github.com/ge-high-assurance/RACK/commit/{commit.number})"
            print(f"\n# Changes for {this_tag}")

    if args.format_for_wiki:
        print("\n- Changes prior to version 4.0 are not tracked.")

    print("\n")
    sys.exit(0)

to_folder = Path(args.to_folder)

if not args.from_folder:
    print("from_folder argument missing, quitting.")
from_folder = Path(args.from_folder)
if not Path.exists(from_folder):
    print("from_folder does not exist, quitting.")
    sys.exit(1)

if not args.to_folder:
    print("to_folder argument missing, quitting.")
if not Path.exists(to_folder):
    print("to_folder does not exist, quitting.")
    sys.exit(1)

for json_file_path in from_folder.glob("*.json"):
    input_file = f"{from_folder}/{json_file_path.name}"
    output_file = f"{to_folder}/{json_file_path.name}"
    logger.info(
        f" Migrating from {stylize_file_name(input_file)} to {stylize_file_name(output_file)}"
    )
    with open(json_file_path) as json_file:
        my_json = semtk.SemTKJSON.parse_raw(json_file.read())
        for commit in commits_to_consider_in_chronological_order:
            commit_number = commit.number
            logger.debug(f"Processing commit {commit_number}")
            for change in commit.changes:
                change.migrate_json(my_json)
        with open(f"{to_folder}/{json_file_path.name}", mode="w") as out_file:
            out_file.write(my_json.json(exclude_unset=True, indent=4))
